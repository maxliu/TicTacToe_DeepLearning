{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import Numpy, TensorFlow, TFLearn, and MNIST data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = \"ttt_data_for_tf.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(fileName, \"rb\") as input_file:\n",
    "    data = cPickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve the training and test data\n",
    "trainX0, trainY0= data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1,  1,  1,  0, -1, -1,  0,  1],\n",
       "       [ 1,  0,  1, -1,  1,  0, -1, -1,  0],\n",
       "       [-1,  1, -1,  0, -1,  1, -1,  0, -1],\n",
       "       [-1,  1, -1, -1,  1,  0,  0, -1, -1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = np.asarray([list(x) for x in trainX0])\n",
    "trainX[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX =  np.apply_along_axis(lambda x: (x+1.0)/2.0, -1,trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainY = np.asarray(trainY0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0. ,  1. , ...,  0. ,  0.5,  1. ],\n",
       "       [ 1. ,  0.5,  1. , ...,  0. ,  0. ,  0.5],\n",
       "       [ 0. ,  1. ,  0. , ...,  0. ,  0.5,  0. ],\n",
       "       ..., \n",
       "       [ 0.5,  0.5,  0. , ...,  0. ,  1. ,  1. ],\n",
       "       [ 0.5,  0. ,  1. , ...,  0. ,  0.5,  0. ],\n",
       "       [ 1. ,  1. ,  0. , ...,  0.5,  0.5,  0. ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Inputs\n",
    "    net = tflearn.input_data([None, trainX.shape[1]],dtype=tf.float32)\n",
    "\n",
    "    # Hidden layer(s)\n",
    "    net = tflearn.fully_connected(net, 1000, activation='ReLU')\n",
    "\n",
    "    # Output layer and training model\n",
    "    net = tflearn.fully_connected(net, trainY.shape[1], activation='softmax')\n",
    "    net = tflearn.regression(net, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy')\n",
    "    # softmax\n",
    "    # ReLU\n",
    "    # categorical_crossentropy\n",
    "    #sgd adam\n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build the model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m1.18702\u001b[0m\u001b[0m | time: 0.302s\n",
      "| Adam | epoch: 010 | loss: 1.18702 - acc: 0.5059 -- iter: 4050/4065\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m1.17920\u001b[0m\u001b[0m | time: 1.310s\n",
      "| Adam | epoch: 010 | loss: 1.17920 - acc: 0.5134 | val_loss: 1.28573 - val_acc: 0.4912 -- iter: 4065/4065\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=50, n_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy: ', 0.55899933584237327)\n"
     ]
    }
   ],
   "source": [
    "# Compare the labels that our model predicts with the actual labels\n",
    "\n",
    "# Find the indices of the most confident prediction for each item. That tells us the predicted digit for that sample.\n",
    "predictions = np.array(model.predict(trainX)).argmax(axis=1)\n",
    "\n",
    "# Calculate the accuracy, which is the percentage of times the predicated labels matched the actual labels\n",
    "actual = trainY.argmax(axis=1)\n",
    "test_accuracy = np.mean(predictions == actual, axis=0)\n",
    "\n",
    "# Print out the result\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   1.   0.5  0.5  0.5  0.   0.   1.   1. ]\n",
      "[0 0 0 0 0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  3.71036619e-01,   3.35401237e-05,   2.48189695e-04,\n",
       "          5.72656421e-03,   1.23833062e-03,   3.41053247e-01,\n",
       "          2.79887348e-01,   4.00184479e-04,   3.75969510e-04]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=200\n",
    "print trainX[n]\n",
    "print trainY[n]\n",
    "model.predict([trainX[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.05996311e-01,   8.67184062e-05,   1.71194595e-04,\n",
       "          5.29271085e-03,   2.50784378e-03,   2.65984833e-01,\n",
       "          1.01672579e-03,   1.15068793e-01,   3.87488026e-03]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([trainX[1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 4, ..., 2, 6, 4])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
